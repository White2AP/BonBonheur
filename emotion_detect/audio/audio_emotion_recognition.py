#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éŸ³é¢‘æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ
åŸºäºMFCCç‰¹å¾å’Œæœºå™¨å­¦ä¹ æ¨¡å‹è¿›è¡ŒéŸ³é¢‘æƒ…ç»ªåˆ†ç±»
æ”¯æŒçš„æƒ…ç»ªï¼šangry, happy, neutral, sad
"""

import os
import numpy as np
import pandas as pd
import librosa
import librosa.display
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import Pipeline
import joblib
import warnings
warnings.filterwarnings('ignore')

class AudioEmotionRecognizer:
    """éŸ³é¢‘æƒ…ç»ªè¯†åˆ«å™¨"""
    
    def __init__(self, dataset_path=None):
        """
        åˆå§‹åŒ–éŸ³é¢‘æƒ…ç»ªè¯†åˆ«å™¨
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„ï¼ˆå¯é€‰ï¼Œä»…è®­ç»ƒæ—¶éœ€è¦ï¼‰
        """
        self.dataset_path = dataset_path or "Dataset/RAVDESS_1s_4categories"
        self.emotions = ['angry', 'happy', 'neutral', 'sad']
        self.model = None
        self.scaler = None
        self.label_encoder = None
        self.feature_columns = None
        
        # MFCCå‚æ•°
        self.n_mfcc = 13
        self.n_fft = 2048
        self.hop_length = 512
        self.sample_rate = 22050
        
        # è¯­éŸ³è½¬æ–‡æœ¬ï¼ˆç®€å•å®ç°ï¼‰
        self.speech_to_text_enabled = False
        try:
            import speech_recognition as sr
            self.recognizer = sr.Recognizer()
            self.speech_to_text_enabled = True
        except ImportError:
            self.recognizer = None
    
    def extract_mfcc_features(self, audio_path, duration=None):
        """
        æå–MFCCç‰¹å¾
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            duration: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å®Œæ•´éŸ³é¢‘
            
        Returns:
            numpy.ndarray: MFCCç‰¹å¾å‘é‡
        """
        try:
            # åŠ è½½éŸ³é¢‘æ–‡ä»¶
            y, sr = librosa.load(audio_path, duration=duration, sr=self.sample_rate)
            
            # å¦‚æœéŸ³é¢‘å¤ªçŸ­ï¼Œè¿›è¡Œå¡«å……
            if len(y) < self.sample_rate * 0.5:  # å°‘äº0.5ç§’
                y = np.pad(y, (0, int(self.sample_rate * 0.5) - len(y)), mode='constant')
            
            # æå–MFCCç‰¹å¾
            mfccs = librosa.feature.mfcc(
                y=y, 
                sr=sr, 
                n_mfcc=self.n_mfcc,
                n_fft=self.n_fft,
                hop_length=self.hop_length
            )
            
            # è®¡ç®—ç»Ÿè®¡ç‰¹å¾
            mfcc_features = []
            
            # å¯¹æ¯ä¸ªMFCCç³»æ•°è®¡ç®—ç»Ÿè®¡é‡
            for i in range(self.n_mfcc):
                mfcc_coeff = mfccs[i]
                mfcc_features.extend([
                    np.mean(mfcc_coeff),      # å‡å€¼
                    np.std(mfcc_coeff),       # æ ‡å‡†å·®
                    np.max(mfcc_coeff),       # æœ€å¤§å€¼
                    np.min(mfcc_coeff),       # æœ€å°å€¼
                    np.median(mfcc_coeff),    # ä¸­ä½æ•°
                ])
            
            # æ·»åŠ å…¶ä»–éŸ³é¢‘ç‰¹å¾
            # é›¶äº¤å‰ç‡
            zcr = librosa.feature.zero_crossing_rate(y)[0]
            mfcc_features.extend([
                np.mean(zcr),
                np.std(zcr)
            ])
            
            # è°±è´¨å¿ƒ
            spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
            mfcc_features.extend([
                np.mean(spectral_centroids),
                np.std(spectral_centroids)
            ])
            
            # è°±å¸¦å®½
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]
            mfcc_features.extend([
                np.mean(spectral_bandwidth),
                np.std(spectral_bandwidth)
            ])
            
            # è°±æ»šé™
            spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]
            mfcc_features.extend([
                np.mean(spectral_rolloff),
                np.std(spectral_rolloff)
            ])
            
            # RMSèƒ½é‡
            rms = librosa.feature.rms(y=y)[0]
            mfcc_features.extend([
                np.mean(rms),
                np.std(rms)
            ])
            
            return np.array(mfcc_features)
            
        except Exception as e:
            print(f"æå–ç‰¹å¾æ—¶å‡ºé”™ {audio_path}: {e}")
            return None
    
    def speech_to_text(self, audio_path):
        """
        è¯­éŸ³è½¬æ–‡æœ¬
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: è¯†åˆ«çš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›ç©ºå­—ç¬¦ä¸²
        """
        if not self.speech_to_text_enabled:
            return ""
        
        try:
            import speech_recognition as sr
            
            # ä½¿ç”¨speech_recognitionåº“
            with sr.AudioFile(audio_path) as source:
                audio = self.recognizer.record(source)
                text = self.recognizer.recognize_google(audio, language='zh-CN')
                return text
        except Exception as e:
            # è¯­éŸ³è½¬æ–‡æœ¬å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
            return ""
    
    def load_dataset(self):
        """
        åŠ è½½æ•°æ®é›†å¹¶æå–ç‰¹å¾
        
        Returns:
            tuple: (ç‰¹å¾çŸ©é˜µ, æ ‡ç­¾æ•°ç»„)
        """
        if not self.dataset_path or not os.path.exists(self.dataset_path):
            raise ValueError(f"æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {self.dataset_path}")
            
        print("ğŸµ å¼€å§‹åŠ è½½æ•°æ®é›†å¹¶æå–ç‰¹å¾...")
        
        features = []
        labels = []
        file_paths = []
        
        for emotion in self.emotions:
            emotion_path = os.path.join(self.dataset_path, emotion)
            if not os.path.exists(emotion_path):
                print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°æƒ…ç»ªæ–‡ä»¶å¤¹ {emotion_path}")
                continue
                
            print(f"ğŸ“ å¤„ç† {emotion} æƒ…ç»ª...")
            emotion_files = [f for f in os.listdir(emotion_path) if f.endswith(('.wav', '.mp3'))]
            
            for i, file_name in enumerate(emotion_files):
                file_path = os.path.join(emotion_path, file_name)
                
                # æå–ç‰¹å¾
                feature_vector = self.extract_mfcc_features(file_path)
                
                if feature_vector is not None:
                    features.append(feature_vector)
                    labels.append(emotion)
                    file_paths.append(file_path)
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 50 == 0:
                    print(f"  å·²å¤„ç† {i + 1}/{len(emotion_files)} ä¸ªæ–‡ä»¶")
            
            print(f"  âœ… {emotion} å®Œæˆï¼Œå…± {len([l for l in labels if l == emotion])} ä¸ªæ ·æœ¬")
        
        if not features:
            raise ValueError("æ²¡æœ‰æˆåŠŸæå–åˆ°ä»»ä½•ç‰¹å¾ï¼Œè¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„å’Œæ–‡ä»¶æ ¼å¼")
        
        features = np.array(features)
        labels = np.array(labels)
        
        print(f"\nğŸ“Š æ•°æ®é›†åŠ è½½å®Œæˆ:")
        print(f"  æ€»æ ·æœ¬æ•°: {len(features)}")
        print(f"  ç‰¹å¾ç»´åº¦: {features.shape[1]}")
        print(f"  æƒ…ç»ªåˆ†å¸ƒ: {dict(zip(*np.unique(labels, return_counts=True)))}")
        
        return features, labels, file_paths
    
    def prepare_data(self, features, labels, test_size=0.2, random_state=42):
        """
        å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        
        Args:
            features: ç‰¹å¾çŸ©é˜µ
            labels: æ ‡ç­¾æ•°ç»„
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            random_state: éšæœºç§å­
            
        Returns:
            tuple: è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        """
        print("ğŸ”„ å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®...")
        
        # æ ‡ç­¾ç¼–ç 
        self.label_encoder = LabelEncoder()
        labels_encoded = self.label_encoder.fit_transform(labels)
        
        # æ•°æ®åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            features, labels_encoded, 
            test_size=test_size, 
            random_state=random_state,
            stratify=labels_encoded
        )
        
        # ç‰¹å¾æ ‡å‡†åŒ–
        self.scaler = StandardScaler()
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ä¿å­˜ç‰¹å¾åˆ—å
        self.feature_columns = [f'feature_{i}' for i in range(features.shape[1])]
        
        print(f"  è®­ç»ƒé›†: {X_train_scaled.shape[0]} æ ·æœ¬")
        print(f"  æµ‹è¯•é›†: {X_test_scaled.shape[0]} æ ·æœ¬")
        
        return X_train_scaled, X_test_scaled, y_train, y_test
    
    def train_models(self, X_train, y_train):
        """
        è®­ç»ƒå¤šä¸ªæ¨¡å‹å¹¶é€‰æ‹©æœ€ä½³æ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒæ ‡ç­¾
            
        Returns:
            dict: è®­ç»ƒç»“æœ
        """
        print("ğŸ¤– å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        
        # å®šä¹‰æ¨¡å‹
        models = {
            'RandomForest': RandomForestClassifier(random_state=42),
            'SVM': SVC(random_state=42, probability=True),
            'GradientBoosting': GradientBoostingClassifier(random_state=42),
            'MLP': MLPClassifier(random_state=42, max_iter=1000)
        }
        
        # å®šä¹‰å‚æ•°ç½‘æ ¼
        param_grids = {
            'RandomForest': {
                'n_estimators': [100, 200],
                'max_depth': [10, 20, None],
                'min_samples_split': [2, 5]
            },
            'SVM': {
                'C': [0.1, 1, 10],
                'gamma': ['scale', 'auto'],
                'kernel': ['rbf', 'linear']
            },
            'GradientBoosting': {
                'n_estimators': [100, 200],
                'learning_rate': [0.05, 0.1],
                'max_depth': [3, 5]
            },
            'MLP': {
                'hidden_layer_sizes': [(100,), (100, 50), (200, 100)],
                'alpha': [0.0001, 0.001],
                'learning_rate': ['constant', 'adaptive']
            }
        }
        
        results = {}
        best_score = 0
        best_model_name = None
        
        for model_name, model in models.items():
            print(f"\nğŸ”§ è®­ç»ƒ {model_name}...")
            
            # ç½‘æ ¼æœç´¢
            grid_search = GridSearchCV(
                model, 
                param_grids[model_name],
                cv=5,
                scoring='accuracy',
                n_jobs=-1,
                verbose=0
            )
            
            grid_search.fit(X_train, y_train)
            
            # äº¤å‰éªŒè¯è¯„åˆ†
            cv_scores = cross_val_score(
                grid_search.best_estimator_, 
                X_train, y_train, 
                cv=5, 
                scoring='accuracy'
            )
            
            results[model_name] = {
                'model': grid_search.best_estimator_,
                'best_params': grid_search.best_params_,
                'cv_score': cv_scores.mean(),
                'cv_std': cv_scores.std()
            }
            
            print(f"  æœ€ä½³å‚æ•°: {grid_search.best_params_}")
            print(f"  äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")
            
            # æ›´æ–°æœ€ä½³æ¨¡å‹
            if cv_scores.mean() > best_score:
                best_score = cv_scores.mean()
                best_model_name = model_name
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        self.model = results[best_model_name]['model']
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best_model_name} (å‡†ç¡®ç‡: {best_score:.4f})")
        
        return results
    
    def evaluate_model(self, X_test, y_test):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•æ ‡ç­¾
            
        Returns:
            dict: è¯„ä¼°ç»“æœ
        """
        print("\nğŸ“Š è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
        
        # é¢„æµ‹
        y_pred = self.model.predict(X_test)
        
        # è®¡ç®—å‡†ç¡®ç‡
        accuracy = accuracy_score(y_test, y_pred)
        
        # åˆ†ç±»æŠ¥å‘Š
        emotion_names = self.label_encoder.classes_
        report = classification_report(
            y_test, y_pred, 
            target_names=emotion_names,
            output_dict=True
        )
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_test, y_pred)
        
        print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f}")
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred, target_names=emotion_names))
        
        return {
            'accuracy': accuracy,
            'classification_report': report,
            'confusion_matrix': cm,
            'emotion_names': emotion_names
        }
    
    def plot_confusion_matrix(self, cm, emotion_names, save_path=None):
        """
        ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        
        Args:
            cm: æ··æ·†çŸ©é˜µ
            emotion_names: æƒ…ç»ªåç§°
            save_path: ä¿å­˜è·¯å¾„
        """
        plt.figure(figsize=(8, 6))
        sns.heatmap(
            cm, 
            annot=True, 
            fmt='d', 
            cmap='Blues',
            xticklabels=emotion_names,
            yticklabels=emotion_names
        )
        plt.title('éŸ³é¢‘æƒ…ç»ªè¯†åˆ«æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        
        if save_path:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(save_path), exist_ok=True)
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()
    
    def predict_emotion(self, audio_path):
        """
        é¢„æµ‹å•ä¸ªéŸ³é¢‘æ–‡ä»¶çš„æƒ…ç»ª
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: é¢„æµ‹ç»“æœï¼ŒåŒ…å«emotion, confidence, transcriptionç­‰å­—æ®µ
        """
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model() æ–¹æ³•")
        
        # æå–ç‰¹å¾
        features = self.extract_mfcc_features(audio_path)
        if features is None:
            return {
                'emotion': 'neutral',
                'confidence': 0.0,
                'transcription': '',
                'error': 'ç‰¹å¾æå–å¤±è´¥'
            }
        
        try:
            # æ ‡å‡†åŒ–
            features_scaled = self.scaler.transform(features.reshape(1, -1))
            
            # é¢„æµ‹
            prediction = self.model.predict(features_scaled)[0]
            
            # è·å–æ¦‚ç‡ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
            if hasattr(self.model, 'predict_proba'):
                probabilities = self.model.predict_proba(features_scaled)[0]
                confidence = float(max(probabilities))
            else:
                # å¦‚æœæ¨¡å‹ä¸æ”¯æŒæ¦‚ç‡é¢„æµ‹ï¼Œä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦
                confidence = 0.8
            
            # è§£ç æ ‡ç­¾
            emotion = self.label_encoder.inverse_transform([prediction])[0]
            
            # è¯­éŸ³è½¬æ–‡æœ¬
            transcription = self.speech_to_text(audio_path)
            
            # æ„å»ºç»“æœ
            result = {
                'emotion': emotion,
                'confidence': confidence,
                'transcription': transcription,
                'raw_emotion': emotion,
                'method': 'audio'
            }
            
            return result
            
        except Exception as e:
            return {
                'emotion': 'neutral',
                'confidence': 0.0,
                'transcription': '',
                'error': f'é¢„æµ‹å¤±è´¥: {str(e)}'
            }
    
    def save_model(self, model_path="models/audio_emotion_model.pkl"):
        """
        ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹ä¿å­˜è·¯å¾„
        """
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'feature_columns': self.feature_columns,
            'emotions': self.emotions,
            'mfcc_params': {
                'n_mfcc': self.n_mfcc,
                'n_fft': self.n_fft,
                'hop_length': self.hop_length,
                'sample_rate': self.sample_rate
            }
        }
        
        joblib.dump(model_data, model_path)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
    
    def load_model(self, model_path="models/audio_emotion_model.pkl"):
        """
        åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        
        model_data = joblib.load(model_path)
        
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.label_encoder = model_data['label_encoder']
        self.feature_columns = model_data['feature_columns']
        self.emotions = model_data['emotions']
        
        # åŠ è½½MFCCå‚æ•°
        mfcc_params = model_data['mfcc_params']
        self.n_mfcc = mfcc_params['n_mfcc']
        self.n_fft = mfcc_params['n_fft']
        self.hop_length = mfcc_params['hop_length']
        self.sample_rate = mfcc_params['sample_rate']
        
        print(f"âœ… æ¨¡å‹å·²ä» {model_path} åŠ è½½")
    
    def train(self, test_size=0.2, save_model=True):
        """
        å®Œæ•´çš„è®­ç»ƒæµç¨‹
        
        Args:
            test_size: æµ‹è¯•é›†æ¯”ä¾‹
            save_model: æ˜¯å¦ä¿å­˜æ¨¡å‹
            
        Returns:
            dict: è®­ç»ƒå’Œè¯„ä¼°ç»“æœ
        """
        print("ğŸš€ å¼€å§‹éŸ³é¢‘æƒ…ç»ªè¯†åˆ«æ¨¡å‹è®­ç»ƒ...")
        
        # 1. åŠ è½½æ•°æ®é›†
        features, labels, file_paths = self.load_dataset()
        
        # 2. å‡†å¤‡æ•°æ®
        X_train, X_test, y_train, y_test = self.prepare_data(
            features, labels, test_size=test_size
        )
        
        # 3. è®­ç»ƒæ¨¡å‹
        training_results = self.train_models(X_train, y_train)
        
        # 4. è¯„ä¼°æ¨¡å‹
        evaluation_results = self.evaluate_model(X_test, y_test)
        
        # 5. ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        self.plot_confusion_matrix(
            evaluation_results['confusion_matrix'],
            evaluation_results['emotion_names'],
            save_path="models/confusion_matrix.png"
        )
        
        # 6. ä¿å­˜æ¨¡å‹
        if save_model:
            self.save_model()
        
        print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼")
        
        return {
            'training_results': training_results,
            'evaluation_results': evaluation_results
        }

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´çš„è®­ç»ƒå’Œé¢„æµ‹æµç¨‹"""
    print("ğŸµ éŸ³é¢‘æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿ")
    print("=" * 50)
    
    # åˆ›å»ºè¯†åˆ«å™¨
    recognizer = AudioEmotionRecognizer()
    
    try:
        # è®­ç»ƒæ¨¡å‹
        results = recognizer.train()
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        accuracy = results['evaluation_results']['accuracy']
        print(f"\nğŸ“ˆ æœ€ç»ˆæ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}")
        
        # æ¼”ç¤ºé¢„æµ‹åŠŸèƒ½
        print("\nğŸ”® é¢„æµ‹æ¼”ç¤º:")
        dataset_path = recognizer.dataset_path
        
        # ä»æ¯ä¸ªæƒ…ç»ªç±»åˆ«ä¸­é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶è¿›è¡Œé¢„æµ‹æ¼”ç¤º
        for emotion in recognizer.emotions:
            emotion_path = os.path.join(dataset_path, emotion)
            if os.path.exists(emotion_path):
                files = [f for f in os.listdir(emotion_path) if f.endswith(('.wav', '.mp3'))]
                if files:
                    test_file = os.path.join(emotion_path, files[0])
                    result = recognizer.predict_emotion(test_file)
                    if result:
                        print(f"  æ–‡ä»¶: {files[0]}")
                        print(f"  çœŸå®æƒ…ç»ª: {emotion}")
                        print(f"  é¢„æµ‹æƒ…ç»ª: {result['emotion']}")
                        print(f"  ç½®ä¿¡åº¦: {result['confidence']:.4f}")
                        print()
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥æ•°æ®é›†è·¯å¾„å’Œæ–‡ä»¶æ ¼å¼")

if __name__ == "__main__":
    main() 