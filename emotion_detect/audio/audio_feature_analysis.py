#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
éŸ³é¢‘ç‰¹å¾åˆ†æå·¥å…·
ç”¨äºåˆ†æMFCCç‰¹å¾å’Œå…¶ä»–éŸ³é¢‘ç‰¹å¾çš„åˆ†å¸ƒå’Œé‡è¦æ€§
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import librosa
import librosa.display
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.feature_selection import SelectKBest, f_classif
from audio_emotion_recognition import AudioEmotionRecognizer
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class AudioFeatureAnalyzer:
    """éŸ³é¢‘ç‰¹å¾åˆ†æå™¨"""
    
    def __init__(self, dataset_path="Dataset/RAVDESS_1s_4categories"):
        """
        åˆå§‹åŒ–éŸ³é¢‘ç‰¹å¾åˆ†æå™¨
        
        Args:
            dataset_path: æ•°æ®é›†è·¯å¾„
        """
        self.dataset_path = dataset_path
        self.emotions = ['angry', 'happy', 'neutral', 'sad']
        self.recognizer = AudioEmotionRecognizer(dataset_path)
        
        # ç‰¹å¾åç§°
        self.feature_names = self._generate_feature_names()
    
    def _generate_feature_names(self):
        """ç”Ÿæˆç‰¹å¾åç§°"""
        feature_names = []
        
        # MFCCç‰¹å¾åç§°
        for i in range(13):  # 13ä¸ªMFCCç³»æ•°
            feature_names.extend([
                f'MFCC_{i+1}_mean',
                f'MFCC_{i+1}_std',
                f'MFCC_{i+1}_max',
                f'MFCC_{i+1}_min',
                f'MFCC_{i+1}_median'
            ])
        
        # å…¶ä»–ç‰¹å¾åç§°
        feature_names.extend([
            'ZCR_mean', 'ZCR_std',
            'SpectralCentroid_mean', 'SpectralCentroid_std',
            'SpectralBandwidth_mean', 'SpectralBandwidth_std',
            'SpectralRolloff_mean', 'SpectralRolloff_std',
            'RMS_mean', 'RMS_std'
        ])
        
        return feature_names
    
    def load_and_analyze_features(self):
        """åŠ è½½æ•°æ®å¹¶åˆ†æç‰¹å¾"""
        print("ğŸ” å¼€å§‹ç‰¹å¾åˆ†æ...")
        
        # åŠ è½½æ•°æ®
        features, labels, file_paths = self.recognizer.load_dataset()
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(features, columns=self.feature_names)
        df['emotion'] = labels
        df['file_path'] = file_paths
        
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"  æ ·æœ¬æ•°: {len(df)}")
        print(f"  ç‰¹å¾æ•°: {len(self.feature_names)}")
        print(f"  æƒ…ç»ªåˆ†å¸ƒ: {df['emotion'].value_counts().to_dict()}")
        
        return df
    
    def plot_feature_distributions(self, df, save_path="analysis"):
        """ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾"""
        print("ğŸ“ˆ ç»˜åˆ¶ç‰¹å¾åˆ†å¸ƒå›¾...")
        
        os.makedirs(save_path, exist_ok=True)
        
        # é€‰æ‹©ä¸€äº›é‡è¦çš„MFCCç‰¹å¾è¿›è¡Œå¯è§†åŒ–
        important_features = [
            'MFCC_1_mean', 'MFCC_2_mean', 'MFCC_3_mean',
            'ZCR_mean', 'SpectralCentroid_mean', 'RMS_mean'
        ]
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.ravel()
        
        for i, feature in enumerate(important_features):
            for emotion in self.emotions:
                emotion_data = df[df['emotion'] == emotion][feature]
                axes[i].hist(emotion_data, alpha=0.6, label=emotion, bins=20)
            
            axes[i].set_title(f'{feature} åˆ†å¸ƒ')
            axes[i].set_xlabel('ç‰¹å¾å€¼')
            axes[i].set_ylabel('é¢‘æ¬¡')
            axes[i].legend()
            axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{save_path}/feature_distributions.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ç‰¹å¾åˆ†å¸ƒå›¾å·²ä¿å­˜åˆ°: {save_path}/feature_distributions.png")
    
    def plot_correlation_matrix(self, df, save_path="analysis"):
        """ç»˜åˆ¶ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ"""
        print("ğŸ”— ç»˜åˆ¶ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ...")
        
        os.makedirs(save_path, exist_ok=True)
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µï¼ˆåªåŒ…å«æ•°å€¼ç‰¹å¾ï¼‰
        numeric_features = df.select_dtypes(include=[np.number]).columns
        correlation_matrix = df[numeric_features].corr()
        
        # ç»˜åˆ¶çƒ­åŠ›å›¾
        plt.figure(figsize=(20, 16))
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(
            correlation_matrix, 
            mask=mask,
            annot=False, 
            cmap='coolwarm', 
            center=0,
            square=True,
            fmt='.2f'
        )
        plt.title('éŸ³é¢‘ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ')
        plt.tight_layout()
        plt.savefig(f"{save_path}/correlation_matrix.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ç›¸å…³æ€§çŸ©é˜µå·²ä¿å­˜åˆ°: {save_path}/correlation_matrix.png")
        
        return correlation_matrix
    
    def analyze_feature_importance(self, df, save_path="analysis"):
        """åˆ†æç‰¹å¾é‡è¦æ€§"""
        print("â­ åˆ†æç‰¹å¾é‡è¦æ€§...")
        
        os.makedirs(save_path, exist_ok=True)
        
        # å‡†å¤‡æ•°æ®
        X = df[self.feature_names].values
        y = df['emotion'].values
        
        # ä½¿ç”¨Fæ£€éªŒé€‰æ‹©é‡è¦ç‰¹å¾
        selector = SelectKBest(score_func=f_classif, k='all')
        selector.fit(X, y)
        
        # è·å–ç‰¹å¾é‡è¦æ€§åˆ†æ•°
        feature_scores = selector.scores_
        feature_importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance_score': feature_scores
        }).sort_values('importance_score', ascending=False)
        
        # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾
        plt.figure(figsize=(12, 8))
        top_features = feature_importance_df.head(20)
        
        sns.barplot(data=top_features, y='feature', x='importance_score')
        plt.title('Top 20 é‡è¦ç‰¹å¾ (F-score)')
        plt.xlabel('é‡è¦æ€§åˆ†æ•°')
        plt.ylabel('ç‰¹å¾åç§°')
        plt.tight_layout()
        plt.savefig(f"{save_path}/feature_importance.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… ç‰¹å¾é‡è¦æ€§å›¾å·²ä¿å­˜åˆ°: {save_path}/feature_importance.png")
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§æ•°æ®
        feature_importance_df.to_csv(f"{save_path}/feature_importance.csv", index=False)
        print(f"âœ… ç‰¹å¾é‡è¦æ€§æ•°æ®å·²ä¿å­˜åˆ°: {save_path}/feature_importance.csv")
        
        return feature_importance_df
    
    def plot_pca_analysis(self, df, save_path="analysis"):
        """PCAé™ç»´åˆ†æ"""
        print("ğŸ”„ è¿›è¡ŒPCAé™ç»´åˆ†æ...")
        
        os.makedirs(save_path, exist_ok=True)
        
        # å‡†å¤‡æ•°æ®
        X = df[self.feature_names].values
        y = df['emotion'].values
        
        # æ ‡å‡†åŒ–
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # PCAé™ç»´
        pca = PCA()
        X_pca = pca.fit_transform(X_scaled)
        
        # ç»˜åˆ¶è§£é‡Šæ–¹å·®æ¯”ä¾‹
        plt.figure(figsize=(12, 5))
        
        # å­å›¾1: ç´¯ç§¯è§£é‡Šæ–¹å·®
        plt.subplot(1, 2, 1)
        cumsum_ratio = np.cumsum(pca.explained_variance_ratio_)
        plt.plot(range(1, len(cumsum_ratio) + 1), cumsum_ratio, 'bo-')
        plt.axhline(y=0.95, color='r', linestyle='--', label='95%è§£é‡Šæ–¹å·®')
        plt.xlabel('ä¸»æˆåˆ†æ•°é‡')
        plt.ylabel('ç´¯ç§¯è§£é‡Šæ–¹å·®æ¯”ä¾‹')
        plt.title('PCAç´¯ç§¯è§£é‡Šæ–¹å·®')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2: å‰ä¸¤ä¸ªä¸»æˆåˆ†çš„æ•£ç‚¹å›¾
        plt.subplot(1, 2, 2)
        colors = ['red', 'blue', 'green', 'orange']
        for i, emotion in enumerate(self.emotions):
            mask = y == emotion
            plt.scatter(X_pca[mask, 0], X_pca[mask, 1], 
                       c=colors[i], label=emotion, alpha=0.6)
        
        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} è§£é‡Šæ–¹å·®)')
        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} è§£é‡Šæ–¹å·®)')
        plt.title('å‰ä¸¤ä¸ªä¸»æˆåˆ†æ•£ç‚¹å›¾')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{save_path}/pca_analysis.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… PCAåˆ†æå›¾å·²ä¿å­˜åˆ°: {save_path}/pca_analysis.png")
        
        # æ‰¾åˆ°95%è§£é‡Šæ–¹å·®æ‰€éœ€çš„ä¸»æˆåˆ†æ•°é‡
        n_components_95 = np.argmax(cumsum_ratio >= 0.95) + 1
        print(f"ğŸ“Š 95%è§£é‡Šæ–¹å·®éœ€è¦ {n_components_95} ä¸ªä¸»æˆåˆ†")
        
        return pca, X_pca
    
    def plot_tsne_visualization(self, df, save_path="analysis"):
        """t-SNEå¯è§†åŒ–"""
        print("ğŸ¨ è¿›è¡Œt-SNEå¯è§†åŒ–...")
        
        os.makedirs(save_path, exist_ok=True)
        
        # å‡†å¤‡æ•°æ®
        X = df[self.feature_names].values
        y = df['emotion'].values
        
        # æ ‡å‡†åŒ–
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        
        # å…ˆç”¨PCAé™ç»´åˆ°50ç»´ï¼ˆåŠ é€Ÿt-SNEï¼‰
        pca = PCA(n_components=50)
        X_pca = pca.fit_transform(X_scaled)
        
        # t-SNEé™ç»´
        tsne = TSNE(n_components=2, random_state=42, perplexity=30)
        X_tsne = tsne.fit_transform(X_pca)
        
        # ç»˜åˆ¶t-SNEç»“æœ
        plt.figure(figsize=(10, 8))
        colors = ['red', 'blue', 'green', 'orange']
        
        for i, emotion in enumerate(self.emotions):
            mask = y == emotion
            plt.scatter(X_tsne[mask, 0], X_tsne[mask, 1], 
                       c=colors[i], label=emotion, alpha=0.6, s=50)
        
        plt.xlabel('t-SNE ç»´åº¦ 1')
        plt.ylabel('t-SNE ç»´åº¦ 2')
        plt.title('éŸ³é¢‘ç‰¹å¾ t-SNE å¯è§†åŒ–')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{save_path}/tsne_visualization.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… t-SNEå¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}/tsne_visualization.png")
        
        return X_tsne
    
    def analyze_emotion_characteristics(self, df, save_path="analysis"):
        """åˆ†æå„æƒ…ç»ªçš„ç‰¹å¾ç‰¹ç‚¹"""
        print("ğŸ­ åˆ†æå„æƒ…ç»ªçš„ç‰¹å¾ç‰¹ç‚¹...")
        
        os.makedirs(save_path, exist_ok=True)
        
        # è®¡ç®—å„æƒ…ç»ªçš„ç‰¹å¾ç»Ÿè®¡
        emotion_stats = df.groupby('emotion')[self.feature_names].agg(['mean', 'std'])
        
        # é€‰æ‹©å‡ ä¸ªé‡è¦ç‰¹å¾è¿›è¡Œå¯¹æ¯”
        important_features = [
            'MFCC_1_mean', 'MFCC_2_mean', 'MFCC_3_mean',
            'ZCR_mean', 'SpectralCentroid_mean', 'RMS_mean'
        ]
        
        # ç»˜åˆ¶é›·è¾¾å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12), subplot_kw=dict(projection='polar'))
        axes = axes.ravel()
        
        for i, emotion in enumerate(self.emotions):
            ax = axes[i]
            
            # è·å–è¯¥æƒ…ç»ªçš„ç‰¹å¾å‡å€¼å¹¶æ ‡å‡†åŒ–
            emotion_data = df[df['emotion'] == emotion][important_features].mean()
            
            # æ ‡å‡†åŒ–åˆ°0-1èŒƒå›´
            from sklearn.preprocessing import MinMaxScaler
            scaler = MinMaxScaler()
            all_data = df[important_features].values
            scaler.fit(all_data)
            normalized_data = scaler.transform(emotion_data.values.reshape(1, -1))[0]
            
            # ç»˜åˆ¶é›·è¾¾å›¾
            angles = np.linspace(0, 2 * np.pi, len(important_features), endpoint=False)
            angles = np.concatenate((angles, [angles[0]]))  # é—­åˆå›¾å½¢
            values = np.concatenate((normalized_data, [normalized_data[0]]))
            
            ax.plot(angles, values, 'o-', linewidth=2, label=emotion)
            ax.fill(angles, values, alpha=0.25)
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(important_features, fontsize=8)
            ax.set_ylim(0, 1)
            ax.set_title(f'{emotion.upper()} æƒ…ç»ªç‰¹å¾', fontsize=12, fontweight='bold')
            ax.grid(True)
        
        plt.tight_layout()
        plt.savefig(f"{save_path}/emotion_characteristics.png", dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"âœ… æƒ…ç»ªç‰¹å¾å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {save_path}/emotion_characteristics.png")
        
        # ä¿å­˜ç»Ÿè®¡æ•°æ®
        emotion_stats.to_csv(f"{save_path}/emotion_statistics.csv")
        print(f"âœ… æƒ…ç»ªç»Ÿè®¡æ•°æ®å·²ä¿å­˜åˆ°: {save_path}/emotion_statistics.csv")
        
        return emotion_stats
    
    def generate_analysis_report(self, df, save_path="analysis"):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        os.makedirs(save_path, exist_ok=True)
        
        report = []
        report.append("# éŸ³é¢‘æƒ…ç»ªè¯†åˆ«ç‰¹å¾åˆ†ææŠ¥å‘Š\n")
        report.append(f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now()}\n\n")
        
        # æ•°æ®é›†æ¦‚è§ˆ
        report.append("## 1. æ•°æ®é›†æ¦‚è§ˆ\n")
        report.append(f"- æ€»æ ·æœ¬æ•°: {len(df)}\n")
        report.append(f"- ç‰¹å¾ç»´åº¦: {len(self.feature_names)}\n")
        report.append(f"- æƒ…ç»ªç±»åˆ«: {', '.join(self.emotions)}\n")
        
        emotion_counts = df['emotion'].value_counts()
        report.append("\n### æƒ…ç»ªåˆ†å¸ƒ:\n")
        for emotion, count in emotion_counts.items():
            percentage = count / len(df) * 100
            report.append(f"- {emotion}: {count} æ ·æœ¬ ({percentage:.1f}%)\n")
        
        # ç‰¹å¾ç»Ÿè®¡
        report.append("\n## 2. ç‰¹å¾ç»Ÿè®¡\n")
        numeric_features = df[self.feature_names]
        report.append(f"- ç‰¹å¾å‡å€¼èŒƒå›´: {numeric_features.mean().min():.4f} ~ {numeric_features.mean().max():.4f}\n")
        report.append(f"- ç‰¹å¾æ ‡å‡†å·®èŒƒå›´: {numeric_features.std().min():.4f} ~ {numeric_features.std().max():.4f}\n")
        
        # ç¼ºå¤±å€¼æ£€æŸ¥
        missing_values = df.isnull().sum().sum()
        report.append(f"- ç¼ºå¤±å€¼æ€»æ•°: {missing_values}\n")
        
        # ç‰¹å¾é‡è¦æ€§
        feature_importance = self.analyze_feature_importance(df, save_path)
        top_5_features = feature_importance.head(5)
        report.append("\n## 3. Top 5 é‡è¦ç‰¹å¾\n")
        for idx, row in top_5_features.iterrows():
            report.append(f"- {row['feature']}: {row['importance_score']:.2f}\n")
        
        # æƒ…ç»ªç‰¹å¾åˆ†æ
        report.append("\n## 4. å„æƒ…ç»ªç‰¹å¾ç‰¹ç‚¹\n")
        emotion_stats = df.groupby('emotion')[self.feature_names].mean()
        
        for emotion in self.emotions:
            report.append(f"\n### {emotion.upper()}:\n")
            emotion_features = emotion_stats.loc[emotion]
            top_features = emotion_features.nlargest(3)
            report.append("ä¸»è¦ç‰¹å¾:\n")
            for feature, value in top_features.items():
                report.append(f"- {feature}: {value:.4f}\n")
        
        # å»ºè®®
        report.append("\n## 5. å»ºè®®\n")
        report.append("- è€ƒè™‘ä½¿ç”¨ç‰¹å¾é€‰æ‹©æ–¹æ³•å‡å°‘ç‰¹å¾ç»´åº¦\n")
        report.append("- å¯ä»¥å°è¯•æ·±åº¦å­¦ä¹ æ–¹æ³•æå–æ›´é«˜çº§çš„ç‰¹å¾\n")
        report.append("- å»ºè®®å¢åŠ æ•°æ®å¢å¼ºæŠ€æœ¯æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›\n")
        
        # ä¿å­˜æŠ¥å‘Š
        with open(f"{save_path}/analysis_report.md", 'w', encoding='utf-8') as f:
            f.writelines(report)
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {save_path}/analysis_report.md")
        
        return ''.join(report)
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„ç‰¹å¾åˆ†ææµç¨‹"""
        print("ğŸš€ å¼€å§‹å®Œæ•´çš„éŸ³é¢‘ç‰¹å¾åˆ†æ...")
        print("=" * 60)
        
        # 1. åŠ è½½æ•°æ®
        df = self.load_and_analyze_features()
        
        # 2. ç‰¹å¾åˆ†å¸ƒåˆ†æ
        self.plot_feature_distributions(df)
        
        # 3. ç›¸å…³æ€§åˆ†æ
        self.plot_correlation_matrix(df)
        
        # 4. ç‰¹å¾é‡è¦æ€§åˆ†æ
        self.analyze_feature_importance(df)
        
        # 5. PCAåˆ†æ
        self.plot_pca_analysis(df)
        
        # 6. t-SNEå¯è§†åŒ–
        self.plot_tsne_visualization(df)
        
        # 7. æƒ…ç»ªç‰¹å¾åˆ†æ
        self.analyze_emotion_characteristics(df)
        
        # 8. ç”ŸæˆæŠ¥å‘Š
        self.generate_analysis_report(df)
        
        print("\nğŸ‰ ç‰¹å¾åˆ†æå®Œæˆï¼")
        print("ğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° 'analysis' æ–‡ä»¶å¤¹")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = AudioFeatureAnalyzer()
    analyzer.run_complete_analysis()

if __name__ == "__main__":
    main() 